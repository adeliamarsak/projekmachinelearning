# -*- coding: utf-8 -*-
"""[Klasifikasi] Submission Akhir BMLP_Adelia Marsa Karunika.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j8707cSiCaV97G_t2-BXEWJdgW9Z_ifw

# **1. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

"""# **2. Memuat Dataset dari Hasil Clustering**

Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

# Data Loading
data = pd.read_csv('/content/clustering_results.csv')
data.head()

print("\nInformasi dataset:")
data.info()

"""# **3. Data Splitting**

Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

# Buat instance MinMaxScaler
scaler = MinMaxScaler()

# Normalisasi semua kolom numerik
numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns
data[numeric_columns] = scaler.fit_transform(data[numeric_columns])

# prompt: data splitting

# Separate features (X) and target variable (y)
X = data.drop('Produk_Tabungan', axis=1)  # Assuming 'cluster' is the target variable
y = data['Produk_Tabungan']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Adjust test_size as needed

# Tampilkan bentuk set pelatihan dan set uji untuk memastikan split
print(f"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}")

"""**Training Set**
X_train (6922, 8):

6922: Jumlah sampel (data) yang digunakan untuk melatih model.
8: Jumlah fitur (variabel independen) yang digunakan untuk membuat prediksi.

y_train (6922,):
6922: Jumlah label (variabel target atau dependent) yang sesuai dengan setiap sampel di X_train.

Test Set
X_test (1731, 8):

1731: Jumlah sampel data yang digunakan untuk menguji model.
8: Jumlah fitur yang sama seperti pada training set.

y_test (1731,):

1731: Jumlah label target yang digunakan untuk mengevaluasi performa prediksi model pada test set.

# **4. Membangun Model Klasifikasi**

## **a. Membangun Model Klasifikasi**

Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).
2. Latih model menggunakan data latih.
"""

# Bagian 1: Pelatihan Model
# Definisikan setiap klasifikasi secara terpisah
knn = KNeighborsClassifier().fit(X_train, y_train)
dt = DecisionTreeClassifier().fit(X_train, y_train)
rf = RandomForestClassifier().fit(X_train, y_train)
svm = SVC().fit(X_train, y_train)
nb = GaussianNB().fit(X_train, y_train)

print("Model training selesai.")

# prompt: Latih model menggunakan data latih.

# Bagian 2: Evaluasi Model
models = {
    "K-Nearest Neighbors": knn,
    "Decision Tree": dt,
    "Random Forest": rf,
    "Support Vector Machine": svm,
    "Naive Bayes": nb
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    print(f"\nHasil Evaluasi Model {name}:")
    print(f"Akurasi: {accuracy:.2f}")
    print(f"Presisi: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1-score: {f1:.2f}")
    print("--------------------")

"""1. K-Nearest Neighbors (KNN)

  Akurasi, Presisi, Recall, F1-score: 0.99
  
  Model ini menunjukkan performa yang sangat tinggi dengan nilai evaluasi yang hampir sempurna. Cocok untuk dataset ini jika memiliki distribusi data yang relatif sederhana dan tidak terlalu besar, karena KNN biasanya memerlukan lebih banyak waktu pada dataset besar.

2. Decision Tree

  Akurasi, Presisi, Recall, F1-score: 0.99

  Keunggulan Decision Tree adalah interpretabilitasnya. Dengan hasil ini, model dapat diandalkan untuk prediksi, namun bisa rentan terhadap overfitting jika tidak di-prune dengan baik.

3. Random Forest

  Akurasi, Presisi, Recall, F1-score: 0.99
  
  Random Forest mengurangi risiko overfitting dibandingkan Decision Tree. Performa tinggi ini menunjukkan kekuatan model dalam menangani variabel yang kompleks dan mengurangi varians.

4. Support Vector Machine (SVM)

  Akurasi, Presisi, Recall, F1-score: 1.00

  SVM memberikan performa sempurna pada dataset ini. Ini menunjukkan bahwa dataset memiliki batas-batas kelas yang jelas sehingga SVM dapat memisahkan kelas-kelas dengan optimal. Model ini sangat cocok untuk data dengan margin yang terdefinisi dengan baik, namun bisa menjadi tidak efisien untuk dataset besar.

5. Naive Bayes

  Akurasi: 0.92, Presisi: 0.90, Recall: 0.92, F1-score: 0.89
  
  Performa Naive Bayes lebih rendah dibandingkan model lain. Hal ini mungkin disebabkan oleh asumsi independensi antar fitur yang tidak sepenuhnya berlaku pada dataset ini. Naive Bayes cocok untuk dataset yang memiliki struktur probabilitas sederhana dan distribusi normal.

Tulis narasi atau penjelasan algoritma yang Anda gunakan.

## **b. Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Lakukan prediksi menggunakan data uji.
2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).
3. Buat confusion matrix untuk melihat detail prediksi benar dan salah.
"""

# prompt: Lakukan prediksi menggunakan data uji.

# Prediksi menggunakan data uji untuk setiap model
for name, model in models.items():
    y_pred = model.predict(X_test)
    print(f"\nPrediksi untuk model {name}:")
    print(y_pred) # Menampilkan hasil prediksi

"""Berdasarkan hasil prediksi, berikut adalah analisis singkat untuk setiap model:

1. K-Nearest Neighbors (KNN)

Prediksi [1. 1. 1. ... 0. 0. 1.]

Model KNN memberikan prediksi yang konsisten dengan pola yang terlihat di model lainnya (kecuali Naive Bayes).
Hal ini menunjukkan bahwa KNN mampu menangkap pola dalam data dengan baik.

2. Decision Tree

Prediksi [1. 1. 1. ... 0. 0. 1.]

Prediksi identik dengan KNN, yang menunjukkan bahwa Decision Tree juga berhasil mengenali pola dalam data.
Namun, potensi overfitting perlu diperhatikan, terutama jika model tidak dipangkas (pruned).

3. Random Forest

Prediksi [1. 1. 1. ... 0. 0. 1.]

Random Forest memberikan prediksi yang sama dengan KNN dan Decision Tree.
Hal ini memperkuat keandalan model karena Random Forest menggunakan pendekatan ansambel untuk meningkatkan akurasi dan mengurangi varians.

4. Support Vector Machine (SVM)

Prediksi [1. 1. 1. ... 0. 0. 1.]

Prediksi yang identik dengan KNN, Decision Tree, dan Random Forest menunjukkan bahwa SVM berhasil menemukan margin yang optimal untuk membedakan kelas dalam data.

5. Naive Bayes

Prediksi [1. 1. 1. ... 0. 1. 1.]

Prediksi berbeda pada beberapa data (contohnya baris terakhir, yang diprediksi sebagai 1 oleh Naive Bayes, tetapi 0 oleh model lain).
Hal ini mungkin disebabkan oleh asumsi independensi antar fitur dalam Naive Bayes yang tidak sepenuhnya terpenuhi pada dataset ini.
"""

# prompt: # Fungsi untuk mengevaluasi dan mengembalikan hasil sebagai kamus

def evaluate_models(X_train, y_train, X_test, y_test):
    """
    Evaluates multiple classification models and returns the results as a dictionary.

    Args:
        X_train: Training features.
        y_train: Training target variable.
        X_test: Testing features.
        y_test: Testing target variable.

    Returns:
        A dictionary containing the evaluation results for each model.
    """

    knn = KNeighborsClassifier().fit(X_train, y_train)
    dt = DecisionTreeClassifier().fit(X_train, y_train)
    rf = RandomForestClassifier().fit(X_train, y_train)
    svm = SVC().fit(X_train, y_train)
    nb = GaussianNB().fit(X_train, y_train)

    models = {
        "K-Nearest Neighbors": knn,
        "Decision Tree": dt,
        "Random Forest": rf,
        "Support Vector Machine": svm,
        "Naive Bayes": nb
    }

    results = {}
    for name, model in models.items():
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0) # Handle zero division
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0) # Handle zero division
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0) # Handle zero division

        results[name] = {
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": f1
        }
    return results

# prompt: # Mengevaluasi setiap model dan mengumpulkan hasilnya

# Evaluate the models and collect the results
evaluation_results = evaluate_models(X_train, y_train, X_test, y_test)

# Print or further process the evaluation results
for model_name, metrics in evaluation_results.items():
    print(f"Model: {model_name}")
    print(f"  Accuracy: {metrics['accuracy']:.4f}")
    print(f"  Precision: {metrics['precision']:.4f}")
    print(f"  Recall: {metrics['recall']:.4f}")
    print(f"  F1-score: {metrics['f1_score']:.4f}")

# prompt: # Buat DataFrame untuk meringkas hasil

# Create an empty DataFrame to store the results
summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# ... (your existing code) ...

# Populate the summary DataFrame with the evaluation results
for model_name, metrics in evaluation_results.items():
    summary_df = pd.concat([summary_df, pd.DataFrame({
        'Model': [model_name],
        'Accuracy': [metrics['accuracy']],
        'Precision': [metrics['precision']],
        'Recall': [metrics['recall']],
        'F1-Score': [metrics['f1_score']]
    })], ignore_index=True)

# Display the summary DataFrame
print("\nSummary of Model Performance Without Tuning:")
summary_df

"""Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.

## **c. Tuning Model Klasifikasi (Optional)**

Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik
"""

# prompt: Gunakan GridSearchCV untuk mencari kombinasi hyperparameter terbaik

from sklearn.model_selection import GridSearchCV

# Define the parameter grid for RandomForestClassifier
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Create a GridSearchCV object for RandomForestClassifier
grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='accuracy')

# Fit the GridSearchCV object to the training data
grid_search_rf.fit(X_train, y_train)

# Print the best hyperparameters and the best score
print("Best hyperparameters for RandomForestClassifier:", grid_search_rf.best_params_)
print("Best score for RandomForestClassifier:", grid_search_rf.best_score_)

# Evaluate the best model
best_rf_model = grid_search_rf.best_estimator_
y_pred_rf = best_rf_model.predict(X_test)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Accuracy of best RandomForestClassifier model: {accuracy_rf:.4f}")


# Similarly, you can perform GridSearchCV for other models like KNN, Decision Tree, etc.
# Example for KNN:
param_grid_knn = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='accuracy')
grid_search_knn.fit(X_train, y_train)

print("\nBest hyperparameters for KNeighborsClassifier:", grid_search_knn.best_params_)
print("Best score for KNeighborsClassifier:", grid_search_knn.best_score_)

best_knn_model = grid_search_knn.best_estimator_
y_pred_knn = best_knn_model.predict(X_test)
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print(f"Accuracy of best KNeighborsClassifier model: {accuracy_knn:.4f}")

#Type your code here

"""## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**

Berikut adalah rekomendasi tahapannya.
1. Gunakan model dengan hyperparameter terbaik.
2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa.
"""

# prompt: Evaluasi Model Klasifikasi setelah Tuning

# Create an empty DataFrame to store the results
summary_df_tuned = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# Evaluate the tuned RandomForestClassifier
y_pred_tuned_rf = best_rf_model.predict(X_test)
accuracy_tuned_rf = accuracy_score(y_test, y_pred_tuned_rf)
precision_tuned_rf = precision_score(y_test, y_pred_tuned_rf, average='weighted', zero_division=0)
recall_tuned_rf = recall_score(y_test, y_pred_tuned_rf, average='weighted', zero_division=0)
f1_tuned_rf = f1_score(y_test, y_pred_tuned_rf, average='weighted', zero_division=0)

summary_df_tuned = pd.concat([summary_df_tuned, pd.DataFrame({
    'Model': ['Tuned Random Forest'],
    'Accuracy': [accuracy_tuned_rf],
    'Precision': [precision_tuned_rf],
    'Recall': [recall_tuned_rf],
    'F1-Score': [f1_tuned_rf]
})], ignore_index=True)

# Evaluate the tuned KNN Classifier
y_pred_tuned_knn = best_knn_model.predict(X_test)
accuracy_tuned_knn = accuracy_score(y_test, y_pred_tuned_knn)
precision_tuned_knn = precision_score(y_test, y_pred_tuned_knn, average='weighted', zero_division=0)
recall_tuned_knn = recall_score(y_test, y_pred_tuned_knn, average='weighted', zero_division=0)
f1_tuned_knn = f1_score(y_test, y_pred_tuned_knn, average='weighted', zero_division=0)

summary_df_tuned = pd.concat([summary_df_tuned, pd.DataFrame({
    'Model': ['Tuned KNN'],
    'Accuracy': [accuracy_tuned_knn],
    'Precision': [precision_tuned_knn],
    'Recall': [recall_tuned_knn],
    'F1-Score': [f1_tuned_knn]
})], ignore_index=True)

# Display the summary DataFrame for tuned models
print("\nSummary of Model Performance After Tuning:")
summary_df_tuned

"""**Summary of Model Performance After Tuning**

1. Tuned Random Forest:

  Accuracy: 99.25%; Precision: 99.26%; Recall: 99.25%; F1-Score: 99.23%

2. Tuned K-Nearest Neighbors (KNN):

  Accuracy: 99.36%; Precision: 99.37%; Recall: 99.36%; F1-Score: 99.35%

**Summary of Model Performance Without Tuning**

1. K-Nearest Neighbors (Default):

  Accuracy: 98.90%; Precision: 98.90%; Recall: 98.90%; F1-Score: 98.88%;

2. Random Forest (Default):

  Accuracy: 99.36%; Precision: 99.37%; Recall: 99.36%; F1-Score: 99.35%

**Analisis Performa**

1. Tuned Random Forest vs. Default Random Forest:

Performa sedikit menurun setelah tuning (Accuracy turun dari 99.36% menjadi 99.25%).

Tuning hyperparameter memberikan fleksibilitas, tetapi default parameters sudah optimal pada dataset ini.

Tuned KNN vs. Default KNN:

Peningkatan yang signifikan pada Accuracy, Precision, Recall, dan F1-Score setelah tuning (dari ~98.90% menjadi ~99.36%).
Penggunaan jarak Manhattan dan bobot berbasis jarak membuat model lebih sensitif terhadap pola data.
Kesimpulan:

Random Forest dengan hyperparameter default tetap menjadi model terbaik secara keseluruhan.
Tuned KNN menunjukkan performa kompetitif dan dapat dipilih berdasarkan kebutuhan (misalnya jika interpretasi tetangga relevan).

## **e. Analisis Hasil Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).
2. Identifikasi kelemahan model, seperti:
  - Precision atau Recall rendah untuk kelas tertentu.
  - Apakah model mengalami overfitting atau underfitting?
3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan.

**Summary of Model Performance After Tuning**

1. Tuned Random Forest:

  Accuracy: 99.25%; Precision: 99.26%; Recall: 99.25%; F1-Score: 99.23%

2. Tuned K-Nearest Neighbors (KNN):

  Accuracy: 99.36%; Precision: 99.37%; Recall: 99.36%; F1-Score: 99.35%

**Summary of Model Performance Without Tuning**

1. K-Nearest Neighbors (Default):

  Accuracy: 98.90%; Precision: 98.90%; Recall: 98.90%; F1-Score: 98.88%;

2. Random Forest (Default):

  Accuracy: 99.36%; Precision: 99.37%; Recall: 99.36%; F1-Score: 99.35%

**Analisis Performa**

1. Tuned Random Forest vs. Default Random Forest:

Performa sedikit menurun setelah tuning (Accuracy turun dari 99.36% menjadi 99.25%).

Tuning hyperparameter memberikan fleksibilitas, tetapi default parameters sudah optimal pada dataset ini.

Tuned KNN vs. Default KNN:

Peningkatan yang signifikan pada Accuracy, Precision, Recall, dan F1-Score setelah tuning (dari ~98.90% menjadi ~99.36%).
Penggunaan jarak Manhattan dan bobot berbasis jarak membuat model lebih sensitif terhadap pola data.
Kesimpulan:

Random Forest dengan hyperparameter default tetap menjadi model terbaik secara keseluruhan.
Tuned KNN menunjukkan performa kompetitif dan dapat dipilih berdasarkan kebutuhan (misalnya jika interpretasi tetangga relevan).

Berdasarkan hasil evaluasi yang telah dilakukan, berikut analisis kelemahan model:

1. Precision atau Recall Rendah untuk Kelas Tertentu:

Naive Bayes: Dari semua model yang diuji, Naive Bayes memiliki performa terendah, khususnya akurasi (0.92) dan F1-score (0.89). Ini menunjukkan kemungkinan adanya precision atau recall yang rendah untuk kelas tertentu. Untuk mengidentifikasi kelas mana yang bermasalah, Anda dapat membuat confusion matrix untuk Naive Bayes dan melihat detail prediksi benar dan salah per kelas.

Model Lainnya: Model KNN, Decision Tree, Random Forest, dan SVM menunjukkan performa yang sangat baik dengan akurasi dan F1-score mendekati 1.00. Meskipun demikian, tetap disarankan untuk memeriksa confusion matrix untuk setiap model guna memastikan tidak ada kelas tertentu yang memiliki precision atau recall yang rendah.

2. Overfitting atau Underfitting:

Overfitting: Random Forest yang telah di-tuning menunjukkan sedikit penurunan performa dibandingkan dengan Random Forest default. Hal ini bisa mengindikasikan sedikit overfitting karena model terlalu kompleks dan mencoba menghafal data training, sehingga kurang general pada data testing.
Underfitting: Tidak ada indikasi underfitting pada model-model yang diuji. Underfitting terjadi jika model terlalu sederhana dan tidak mampu menangkap pola dalam data, sehingga performa rendah pada data training dan testing.
Rekomendasi Tindakan Lanjutan

Berikut rekomendasi tindakan lanjutan yang dapat dipertimbangkan:

Analisis Confusion Matrix: Lakukan analisis lebih lanjut pada confusion matrix untuk setiap model, terutama Naive Bayes. Identifikasi kelas-kelas yang memiliki precision atau recall rendah.

Penanganan Kelas Imbalance: Jika terdapat kelas yang memiliki jumlah data yang jauh lebih sedikit dibandingkan kelas lain (class imbalance), Anda dapat mencoba teknik seperti oversampling, undersampling, atau menggunakan algoritma yang robust terhadap class imbalance.

Tuning Hyperparameter Lanjutan: Untuk model yang menunjukkan potensi overfitting (seperti Random Forest yang telah di-tuning), Anda dapat mencoba tuning hyperparameter lebih lanjut untuk mengurangi kompleksitas model dan meningkatkan generalisasi. Pertimbangkan untuk memperluas rentang nilai hyperparameter yang diuji atau menggunakan teknik optimasi hyperparameter seperti Bayesian Optimization.

Mencoba Algoritma Lain: Meskipun model-model yang Anda gunakan telah menunjukkan performa yang baik, Anda dapat mencoba algoritma lain seperti Gradient Boosting, XGBoost, atau LightGBM untuk melihat apakah ada peningkatan performa. Algoritma-algoritma ini dikenal memiliki performa yang kuat dan robust.

Mengumpulkan Data Tambahan: Jika memungkinkan, mengumpulkan data tambahan dapat membantu meningkatkan performa model, terutama jika dataset yang ada relatif kecil atau memiliki class imbalance. Pastikan data tambahan yang dikumpulkan representatif dan berkualitas baik.
"""